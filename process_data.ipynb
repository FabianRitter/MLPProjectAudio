<<<<<<< HEAD
version https://git-lfs.github.com/spec/v1
oid sha256:4acca49b97fbc8c7e8a7fe25d662cfe58bafa60cd824e45e889932e158d15398
size 9812
=======
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from librosa.feature import melspectrogram\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_mel_histogram(mel_hist, number_of_frames=100):\n",
    "    \"\"\"\n",
    "    Return a normalized mel histogram\n",
    "    \n",
    "    mel_hist: \n",
    "    number_of_frames: number of frames to be normalized\n",
    "    \"\"\"   \n",
    "    \n",
    "    if mel_hist.shape[0] > number_of_frames:\n",
    "        return np.delete(mel_hist, \n",
    "                         np.arange(number_of_frames, mel_hist.shape[0]),\n",
    "                         axis=0)\n",
    "    \n",
    "    elif mel_hist.shape[0] < number_of_frames:\n",
    "        mul = int(round(number_of_frames / mel_hist.shape[0], 0)) + 1\n",
    "        repeated_matrix = np.tile(mel_hist.T, mul).T\n",
    "        \n",
    "        if repeated_matrix.shape[0] > number_of_frames:\n",
    "            return np.delete(repeated_matrix, \n",
    "                             np.arange(number_of_frames, repeated_matrix.shape[0]),\n",
    "                             axis=0)\n",
    "        return repeated_matrix\n",
    "    \n",
    "    else:\n",
    "        return mel_hist.flatten()\n",
    "    \n",
    "def convert2mel(audio,base_path):\n",
    "    \"\"\"\n",
    "    Convert raw audio to mel spectrogram\n",
    "    \"\"\"\n",
    "    path = os.path.join(base_path, audio)\n",
    "    fs, data = wavfile.read(path)\n",
    "    data = data.astype(float)\n",
    "    mels = melspectrogram(y=data, sr=44100,\n",
    "                            n_fft=2048, hop_length=512,\n",
    "                            power=2.0, n_mels=96,fmax=16000) \n",
    "    mel_normalized = normalize_mel_histogram(mels.T,number_of_frames)\n",
    "    mel_norm_flat = mel_normalized.flatten()\n",
    "    return mel_norm_flat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHANGE PATHS\n",
    "path_to_metadata = 'data_before/metadata/train_test.csv'\n",
    "base_path = 'data_before/audio_train_test'\n",
    "\n",
    "df_train = pd.read_csv(path_to_metadata)\n",
    "fname = df_train['fname'].values\n",
    "\n",
    "number_of_frames = 100\n",
    "n_mels = 96\n",
    "\n",
    "processes = []\n",
    "\n",
    "all_inputs = np.zeros([len(fname),number_of_frames*n_mels])\n",
    "all_targets = np.zeros(len(fname))\n",
    "all_manually = np.zeros(len(fname))\n",
    "all_noisy_small = np.zeros(len(fname))\n",
    "all_dict = {}\n",
    "    \n",
    "all_inputs = [convert2mel(audio,base_path) for audio in fname]                      \n",
    "    \n",
    "all_dict['inputs'] = all_inputs\n",
    "all_dict['targets'] =  df_train['label']\n",
    "all_dict['manually_verified'] = df_train['manually_verified']\n",
    "all_dict['noisy_small'] = df_train['noisy_small']\n",
    "\n",
    "np.savez('processed_data.npz',**all_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
>>>>>>> 1c10af305007a72a05b313d03ab33339bd7003c9
